{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whatami\n",
    "\n",
    "I am a simple experiment on using actor-critic agent setup for MountainCar problem.\n",
    "Being policy-based method, actor-critic has much better convergence properties that q-learning from the other notebook.\n",
    "\n",
    "## About OpenAI Gym\n",
    "\n",
    "* Its a recently published platform that basicly allows you to train agents in a wide variety of environments with near-identical interface.\n",
    "* This is twice as awesome since now we don't need to write a new wrapper for every game\n",
    "* Go check it out!\n",
    "  * Blog post - https://openai.com/blog/openai-gym-beta/\n",
    "  * Github - https://github.com/openai/gym\n",
    "\n",
    "\n",
    "## New to Lasagne and AgentNet?\n",
    "* We only require surface level knowledge of theano and lasagne, so you can just learn them as you go.\n",
    "* Alternatively, you can find Lasagne tutorials here:\n",
    " * Official mnist example: http://lasagne.readthedocs.io/en/latest/user/tutorial.html\n",
    " * From scratch: https://github.com/ddtm/dl-course/tree/master/Seminar4\n",
    " * From theano: https://github.com/craffel/Lasagne-tutorial/blob/master/examples/tutorial.ipynb\n",
    "* This is pretty much the basic tutorial for AgentNet, so it's okay not to know it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment setup\n",
    "* Here we basically just load the game and check that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=\"floatX=float32\"\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "%env THEANO_FLAGS=\"floatX=float32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#global params.\n",
    "GAME = \"MountainCar-v0\"\n",
    "\n",
    "#number of parallel agents and batch sequence length (frames)\n",
    "N_AGENTS = 1\n",
    "SEQ_LENGTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:37:14,479] Making new env: MountainCar-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.53226085 -0.00094211]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import gym\n",
    "env = gym.make(GAME)\n",
    "obs = env.step(0)[0]\n",
    "action_names = np.array([\"left\",'stop',\"right\"]) #i guess so... i may be wrong\n",
    "state_size = len(obs)\n",
    "print(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic agent setup\n",
    "Here we define a simple agent that maps game images into Qvalues using shallow neural network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_H(p):\n",
    "    return p*np.log(p)+(1.-p)*np.log(1.-p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-17.856653599232011"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1./get_H(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "import lasagne\n",
    "from lasagne.layers import InputLayer,DenseLayer,NonlinearityLayer,batch_norm,dropout\n",
    "#image observation at current tick goes here, shape = (sample_i,x,y,color)\n",
    "observation_layer = InputLayer((None,state_size))\n",
    "\n",
    "dense0 = DenseLayer(observation_layer,100,name='dense1')\n",
    "dense1 = DenseLayer(dense0,256,name='dense2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#a layer that predicts Qvalues\n",
    "\n",
    "policy_layer = DenseLayer(dense1,\n",
    "                   num_units = env.action_space.n,\n",
    "                   nonlinearity=lasagne.nonlinearities.softmax,\n",
    "                   name=\"q-evaluator layer\")\n",
    "\n",
    "\n",
    "V_layer = DenseLayer(dense1, 1, nonlinearity=None,name=\"state values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import theano\n",
    "epsilon = theano.shared(np.float32(0),allow_downcast=True)\n",
    "policy_smooth_layer = NonlinearityLayer(policy_layer,\n",
    "                                        lambda p: (1.-epsilon)*p + epsilon/env.action_space.n)\n",
    "\n",
    "#To pick actions, we use an epsilon-greedy resolver (epsilon is a property)\n",
    "from agentnet.resolver import ProbabilisticResolver\n",
    "action_layer = ProbabilisticResolver(policy_smooth_layer,\n",
    "                                     name=\"e-greedy action picker\",\n",
    "                                     assume_normalized=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finally, agent\n",
    "We declare that this network is and MDP agent with such and such inputs, states and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agentnet.agent import Agent\n",
    "#all together\n",
    "agent = Agent(observation_layers=observation_layer,\n",
    "              policy_estimators=(policy_layer,V_layer),\n",
    "              action_layers=action_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[dense1.W,\n",
       " dense1.b,\n",
       " dense2.W,\n",
       " dense2.b,\n",
       " q-evaluator layer.W,\n",
       " q-evaluator layer.b,\n",
       " state values.W,\n",
       " state values.b]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since it's a single lasagne network, one can get it's weights, output, etc\n",
    "weights = lasagne.layers.get_all_params((action_layer,V_layer),trainable=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and manage a pool of atari sessions to play with\n",
    "\n",
    "* To make training more stable, we shall have an entire batch of game sessions each happening independent of others\n",
    "* Why several parallel agents help training: http://arxiv.org/pdf/1602.01783v1.pdf\n",
    "* Alternative approach: store more sessions: https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:37:15,709] Making new env: MountainCar-v0\n"
     ]
    }
   ],
   "source": [
    "from agentnet.experiments.openai_gym.pool import EnvPool\n",
    "\n",
    "pool = EnvPool(agent,GAME, N_AGENTS,max_size=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['right' 'left' 'left' 'right' 'left' 'left' 'left']]\n",
      "[[-1. -1. -1. -1. -1. -1.  0.]]\n",
      "CPU times: user 4.46 ms, sys: 156 µs, total: 4.62 ms\n",
      "Wall time: 4.04 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#interact for 7 ticks\n",
    "_,action_log,reward_log,_,_,_  = pool.interact(7)\n",
    "\n",
    "\n",
    "print(action_names[action_log])\n",
    "print(reward_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load first sessions (this function calls interact and remembers sessions)\n",
    "pool.update(SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a2c loss\n",
    "\n",
    "Here we define obective function for actor-critic (one-step) RL.\n",
    "\n",
    "* We regularize policy with expected inverse action probabilities (discouraging very small probas) to make objective numerically stable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get agent's Qvalues obtained via experience replay\n",
    "replay = pool.experience_replay.sample_session_batch(100,replace=True)\n",
    "\n",
    "_,_,_,_,(policy_seq,V_seq) = agent.get_sessions(\n",
    "    replay,\n",
    "    session_length=SEQ_LENGTH,\n",
    "    optimize_experience_replay=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get reference Qvalues according to Qlearning algorithm\n",
    "from agentnet.learning import a2c_n_step\n",
    "\n",
    "#crop rewards to [-1,+1] to avoid explosion.\n",
    "#import theano.tensor as T\n",
    "#rewards = T.maximum(-1,T.minimum(rewards,1))\n",
    "\n",
    "#loss for Qlearning = (Q(s,a) - (r+gamma*Q(s',a_max)))^2\n",
    "\n",
    "elwise_mse_loss = a2c_n_step.get_elementwise_objective(policy_seq,V_seq[:,:,0],\n",
    "                                                      replay.actions[0],\n",
    "                                                      replay.rewards,\n",
    "                                                      replay.is_alive,\n",
    "                                                      gamma_or_gammas=0.99,n_steps=1,min_proba=0.01)\n",
    "\n",
    "#compute mean over \"alive\" fragments\n",
    "loss = elwise_mse_loss.sum() / replay.is_alive.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from theano import tensor as T\n",
    "reg_entropy = T.mean((1./policy_seq))\n",
    "loss += 0.01*reg_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute weight updates\n",
    "updates = lasagne.updates.rmsprop(loss,weights,learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#compile train function\n",
    "import theano\n",
    "train_step = theano.function([],loss,updates=updates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:37:26,476] Making new env: MountainCar-v0\n",
      "[2016-11-28 02:37:26,479] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2016-11-28 02:37:26,520] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 200 timesteps with reward=-200.0\n"
     ]
    }
   ],
   "source": [
    "#for MountainCar-v0 evaluation session is cropped to 200 ticks\n",
    "untrained_reward = pool.evaluate(save_path=\"./records\",record_video=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "#video_path=\"./records/openaigym.video.0.7346.video000000.mp4\"\n",
    "\n",
    "#HTML(\"\"\"\n",
    "#<video width=\"640\" height=\"480\" controls>\n",
    "#  <source src=\"{}\" type=\"video/mp4\">\n",
    "#</video>\n",
    "#\"\"\".format(video_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#starting epoch\n",
    "epoch_counter = 1\n",
    "\n",
    "#full game rewards\n",
    "rewards = {epoch_counter:untrained_reward}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 468.91it/s]\n"
     ]
    }
   ],
   "source": [
    "#pre-fill pool\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(range(1000)):\n",
    "    pool.update(SEQ_LENGTH,append=True,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 101/10000 [00:13<22:05,  7.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=100\tepsilon=0.000\treward/step=-0.99992\tpool_size=2001\tloss ma=0.68972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 201/10000 [00:26<22:19,  7.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=200\tepsilon=0.000\treward/step=-0.99989\tpool_size=3001\tloss ma=0.23702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 301/10000 [00:38<20:50,  7.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=300\tepsilon=0.000\treward/step=-0.99981\tpool_size=4001\tloss ma=0.26756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 401/10000 [00:51<22:35,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=400\tepsilon=0.000\treward/step=-0.99967\tpool_size=5001\tloss ma=1.14691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 499/10000 [01:04<20:20,  7.78it/s][2016-11-28 02:38:33,363] Making new env: MountainCar-v0\n",
      "[2016-11-28 02:38:33,367] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=500\tepsilon=0.000\treward/step=-0.99931\tpool_size=6001\tloss ma=0.75610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:38:33,730] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      "  5%|▌         | 501/10000 [01:04<32:28,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -174.600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 601/10000 [01:18<19:08,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=600\tepsilon=0.050\treward/step=-0.99898\tpool_size=7001\tloss ma=0.58279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 701/10000 [01:31<19:18,  8.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=700\tepsilon=0.050\treward/step=-0.99873\tpool_size=8001\tloss ma=0.40981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 800/10000 [01:44<21:04,  7.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=800\tepsilon=0.050\treward/step=-0.99852\tpool_size=9001\tloss ma=0.19286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 901/10000 [01:58<20:33,  7.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=900\tepsilon=0.050\treward/step=-0.99836\tpool_size=10000\tloss ma=0.12155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 999/10000 [02:11<18:57,  7.91it/s][2016-11-28 02:39:40,849] Making new env: MountainCar-v0\n",
      "[2016-11-28 02:39:40,851] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1000\tepsilon=0.050\treward/step=-0.99804\tpool_size=10000\tloss ma=0.12220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:39:41,155] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 10%|█         | 1001/10000 [02:12<30:00,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -146.900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1101/10000 [02:25<21:42,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1100\tepsilon=0.050\treward/step=-0.99773\tpool_size=10000\tloss ma=0.09429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1200/10000 [02:40<21:13,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1200\tepsilon=0.050\treward/step=-0.99742\tpool_size=10000\tloss ma=0.09539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1301/10000 [02:54<20:46,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1300\tepsilon=0.050\treward/step=-0.99714\tpool_size=10000\tloss ma=0.12034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1401/10000 [03:08<20:31,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1400\tepsilon=0.050\treward/step=-0.99691\tpool_size=10000\tloss ma=0.13549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 1499/10000 [03:22<17:50,  7.94it/s][2016-11-28 02:40:51,510] Making new env: MountainCar-v0\n",
      "[2016-11-28 02:40:51,513] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1500\tepsilon=0.050\treward/step=-0.99683\tpool_size=10000\tloss ma=0.16045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:40:51,836] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 15%|█▌        | 1501/10000 [03:22<30:33,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -155.300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1601/10000 [03:36<20:17,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1600\tepsilon=0.050\treward/step=-0.99681\tpool_size=10000\tloss ma=0.17526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1701/10000 [03:50<18:11,  7.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1700\tepsilon=0.050\treward/step=-0.99680\tpool_size=10000\tloss ma=0.16739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1801/10000 [04:04<20:02,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1800\tepsilon=0.050\treward/step=-0.99680\tpool_size=10000\tloss ma=0.21516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 1901/10000 [04:18<20:08,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1900\tepsilon=0.050\treward/step=-0.99678\tpool_size=10000\tloss ma=0.20895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 1999/10000 [04:32<18:50,  7.08it/s][2016-11-28 02:42:01,629] Making new env: MountainCar-v0\n",
      "[2016-11-28 02:42:01,632] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2000\tepsilon=0.050\treward/step=-0.99675\tpool_size=10000\tloss ma=0.22521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:42:01,885] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 20%|██        | 2001/10000 [04:32<25:18,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -123.900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 2101/10000 [04:46<17:01,  7.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2100\tepsilon=0.050\treward/step=-0.99673\tpool_size=10000\tloss ma=0.23742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2201/10000 [04:59<16:29,  7.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2200\tepsilon=0.050\treward/step=-0.99671\tpool_size=10000\tloss ma=0.27355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2301/10000 [05:13<17:09,  7.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2300\tepsilon=0.050\treward/step=-0.99667\tpool_size=10000\tloss ma=0.27669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 2401/10000 [05:27<17:03,  7.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2400\tepsilon=0.050\treward/step=-0.99663\tpool_size=10000\tloss ma=0.31469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 2499/10000 [05:40<17:50,  7.01it/s][2016-11-28 02:43:09,925] Making new env: MountainCar-v0\n",
      "[2016-11-28 02:43:09,927] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2500\tepsilon=0.050\treward/step=-0.99661\tpool_size=10000\tloss ma=0.37594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:43:10,195] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 25%|██▌       | 2501/10000 [05:41<24:28,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -114.100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 2601/10000 [05:55<15:46,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2600\tepsilon=0.050\treward/step=-0.99656\tpool_size=10000\tloss ma=0.42656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 2701/10000 [06:09<19:04,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2700\tepsilon=0.050\treward/step=-0.99653\tpool_size=10000\tloss ma=0.47441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 2801/10000 [06:23<16:05,  7.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2800\tepsilon=0.050\treward/step=-0.99647\tpool_size=10000\tloss ma=0.45972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 2901/10000 [06:37<16:27,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=2900\tepsilon=0.050\treward/step=-0.99643\tpool_size=10000\tloss ma=0.43427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 2999/10000 [06:51<16:41,  6.99it/s][2016-11-28 02:44:20,645] Making new env: MountainCar-v0\n",
      "[2016-11-28 02:44:20,648] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=3000\tepsilon=0.050\treward/step=-0.99645\tpool_size=10000\tloss ma=0.33027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:44:20,971] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 30%|███       | 3001/10000 [06:52<25:45,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -144.100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 3101/10000 [07:06<17:24,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=3100\tepsilon=0.050\treward/step=-0.99647\tpool_size=10000\tloss ma=0.32833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 3201/10000 [07:20<15:13,  7.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=3200\tepsilon=0.050\treward/step=-0.99649\tpool_size=10000\tloss ma=0.31532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3301/10000 [07:34<16:34,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=3300\tepsilon=0.050\treward/step=-0.99652\tpool_size=10000\tloss ma=0.31438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 3401/10000 [07:48<14:59,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=3400\tepsilon=0.050\treward/step=-0.99653\tpool_size=10000\tloss ma=0.31383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 3499/10000 [08:02<13:35,  7.97it/s][2016-11-28 02:45:31,662] Making new env: MountainCar-v0\n",
      "[2016-11-28 02:45:31,665] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=3500\tepsilon=0.050\treward/step=-0.99655\tpool_size=10000\tloss ma=0.31197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:45:31,949] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 35%|███▌      | 3501/10000 [08:02<20:41,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -138.800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 3601/10000 [08:17<14:10,  7.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=3600\tepsilon=0.050\treward/step=-0.99657\tpool_size=10000\tloss ma=0.28223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 3701/10000 [08:31<13:48,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=3700\tepsilon=0.050\treward/step=-0.99657\tpool_size=10000\tloss ma=0.26232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3801/10000 [08:45<13:51,  7.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=3800\tepsilon=0.050\treward/step=-0.99661\tpool_size=10000\tloss ma=0.29449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 3901/10000 [08:59<14:40,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=3900\tepsilon=0.050\treward/step=-0.99661\tpool_size=10000\tloss ma=0.29539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 3999/10000 [09:13<15:50,  6.32it/s][2016-11-28 02:46:42,322] Making new env: MountainCar-v0\n",
      "[2016-11-28 02:46:42,325] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4000\tepsilon=0.050\treward/step=-0.99660\tpool_size=10000\tloss ma=0.26908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:46:42,697] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 40%|████      | 4001/10000 [09:13<22:36,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -144.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 4101/10000 [09:28<13:32,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4100\tepsilon=0.050\treward/step=-0.99656\tpool_size=10000\tloss ma=0.28311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 4201/10000 [09:42<13:28,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4200\tepsilon=0.050\treward/step=-0.99653\tpool_size=10000\tloss ma=0.29194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 4301/10000 [09:56<12:28,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4300\tepsilon=0.050\treward/step=-0.99652\tpool_size=10000\tloss ma=0.28038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4401/10000 [10:10<13:02,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4400\tepsilon=0.050\treward/step=-0.99650\tpool_size=10000\tloss ma=0.28525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 4499/10000 [10:23<11:28,  7.98it/s][2016-11-28 02:47:52,867] Making new env: MountainCar-v0\n",
      "[2016-11-28 02:47:52,870] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4500\tepsilon=0.050\treward/step=-0.99648\tpool_size=10000\tloss ma=0.27434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:47:53,129] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 45%|████▌     | 4501/10000 [10:24<18:04,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -116.900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 4601/10000 [10:38<14:09,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4600\tepsilon=0.050\treward/step=-0.99643\tpool_size=10000\tloss ma=0.29137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 4701/10000 [10:52<11:42,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4700\tepsilon=0.050\treward/step=-0.99639\tpool_size=10000\tloss ma=0.28666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 4801/10000 [11:06<12:36,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4800\tepsilon=0.050\treward/step=-0.99639\tpool_size=10000\tloss ma=0.27687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 4901/10000 [11:21<11:11,  7.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4900\tepsilon=0.050\treward/step=-0.99638\tpool_size=10000\tloss ma=0.25759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 4999/10000 [11:36<11:12,  7.43it/s][2016-11-28 02:49:05,713] Making new env: MountainCar-v0\n",
      "[2016-11-28 02:49:05,715] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5000\tepsilon=0.050\treward/step=-0.99635\tpool_size=10000\tloss ma=0.27514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:49:05,950] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 50%|█████     | 5001/10000 [11:37<16:00,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -112.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 5101/10000 [11:51<11:05,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5100\tepsilon=0.050\treward/step=-0.99634\tpool_size=10000\tloss ma=0.29683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 5201/10000 [12:06<11:58,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5200\tepsilon=0.050\treward/step=-0.99631\tpool_size=10000\tloss ma=0.28892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 5301/10000 [12:24<15:04,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5300\tepsilon=0.050\treward/step=-0.99629\tpool_size=10000\tloss ma=0.29670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 5400/10000 [12:46<17:52,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5400\tepsilon=0.050\treward/step=-0.99628\tpool_size=10000\tloss ma=0.34231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 5499/10000 [13:07<14:27,  5.19it/s][2016-11-28 02:50:36,998] Making new env: MountainCar-v0\n",
      "[2016-11-28 02:50:37,014] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5500\tepsilon=0.050\treward/step=-0.99626\tpool_size=10000\tloss ma=0.33350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:50:37,333] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 55%|█████▌    | 5500/10000 [13:08<21:26,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -118.700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5601/10000 [13:30<11:47,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5600\tepsilon=0.050\treward/step=-0.99626\tpool_size=10000\tloss ma=0.33105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 5701/10000 [13:51<13:56,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5700\tepsilon=0.050\treward/step=-0.99627\tpool_size=10000\tloss ma=0.35541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 5800/10000 [14:12<12:27,  5.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5800\tepsilon=0.050\treward/step=-0.99625\tpool_size=10000\tloss ma=0.36031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 5900/10000 [14:33<16:23,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5900\tepsilon=0.050\treward/step=-0.99624\tpool_size=10000\tloss ma=0.36262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 5999/10000 [14:54<13:10,  5.06it/s][2016-11-28 02:52:23,582] Making new env: MountainCar-v0\n",
      "[2016-11-28 02:52:23,585] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=6000\tepsilon=0.050\treward/step=-0.99624\tpool_size=10000\tloss ma=0.39277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:52:23,906] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 60%|██████    | 6000/10000 [14:54<19:35,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -129.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 6101/10000 [15:15<10:44,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=6100\tepsilon=0.050\treward/step=-0.99624\tpool_size=10000\tloss ma=0.38838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 6201/10000 [15:35<14:50,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=6200\tepsilon=0.050\treward/step=-0.99625\tpool_size=10000\tloss ma=0.38362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 6301/10000 [15:55<10:33,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=6300\tepsilon=0.050\treward/step=-0.99622\tpool_size=10000\tloss ma=0.38480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 6400/10000 [16:15<10:11,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=6400\tepsilon=0.050\treward/step=-0.99621\tpool_size=10000\tloss ma=0.36784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 6499/10000 [16:36<11:15,  5.18it/s][2016-11-28 02:54:05,533] Making new env: MountainCar-v0\n",
      "[2016-11-28 02:54:05,538] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=6500\tepsilon=0.050\treward/step=-0.99622\tpool_size=10000\tloss ma=0.37435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:54:05,889] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 65%|██████▌   | 6501/10000 [16:36<15:53,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -121.800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 6601/10000 [16:53<07:45,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=6600\tepsilon=0.050\treward/step=-0.99622\tpool_size=10000\tloss ma=0.36426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6701/10000 [17:07<07:26,  7.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=6700\tepsilon=0.050\treward/step=-0.99622\tpool_size=10000\tloss ma=0.38318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 6800/10000 [17:21<07:17,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=6800\tepsilon=0.050\treward/step=-0.99620\tpool_size=10000\tloss ma=0.38877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 6901/10000 [17:35<07:29,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=6900\tepsilon=0.050\treward/step=-0.99621\tpool_size=10000\tloss ma=0.36759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 6999/10000 [17:49<07:47,  6.43it/s][2016-11-28 02:55:18,736] Making new env: MountainCar-v0\n",
      "[2016-11-28 02:55:18,739] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=7000\tepsilon=0.050\treward/step=-0.99620\tpool_size=10000\tloss ma=0.38140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:55:18,967] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 70%|███████   | 7001/10000 [17:49<09:51,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -116.100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 7101/10000 [18:04<06:28,  7.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=7100\tepsilon=0.050\treward/step=-0.99620\tpool_size=10000\tloss ma=0.42961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 7201/10000 [18:17<06:03,  7.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=7200\tepsilon=0.050\treward/step=-0.99621\tpool_size=10000\tloss ma=0.42278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 7301/10000 [18:31<06:05,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=7300\tepsilon=0.050\treward/step=-0.99622\tpool_size=10000\tloss ma=0.36798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 7401/10000 [18:45<06:37,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=7400\tepsilon=0.050\treward/step=-0.99622\tpool_size=10000\tloss ma=0.40378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 7499/10000 [18:58<06:12,  6.72it/s][2016-11-28 02:56:28,243] Making new env: MountainCar-v0\n",
      "[2016-11-28 02:56:28,247] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=7500\tepsilon=0.050\treward/step=-0.99621\tpool_size=10000\tloss ma=0.40401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:56:28,522] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 75%|███████▌  | 7501/10000 [18:59<09:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -117.300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 7601/10000 [19:13<05:46,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=7600\tepsilon=0.050\treward/step=-0.99621\tpool_size=10000\tloss ma=0.43037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 7701/10000 [19:31<07:13,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=7700\tepsilon=0.050\treward/step=-0.99624\tpool_size=10000\tloss ma=0.45628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7801/10000 [19:52<08:15,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=7800\tepsilon=0.050\treward/step=-0.99624\tpool_size=10000\tloss ma=0.44923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 7901/10000 [20:13<05:49,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=7900\tepsilon=0.050\treward/step=-0.99625\tpool_size=10000\tloss ma=0.41729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 7999/10000 [20:33<07:14,  4.61it/s][2016-11-28 02:58:03,081] Making new env: MountainCar-v0\n",
      "[2016-11-28 02:58:03,084] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=8000\tepsilon=0.050\treward/step=-0.99623\tpool_size=10000\tloss ma=0.42735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:58:03,327] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 80%|████████  | 8000/10000 [20:34<10:36,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -117.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 8101/10000 [20:55<05:22,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=8100\tepsilon=0.050\treward/step=-0.99622\tpool_size=10000\tloss ma=0.46268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 8200/10000 [21:14<06:06,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=8200\tepsilon=0.050\treward/step=-0.99622\tpool_size=10000\tloss ma=0.48497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 8301/10000 [21:36<05:23,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=8300\tepsilon=0.050\treward/step=-0.99622\tpool_size=10000\tloss ma=0.47917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 8401/10000 [21:56<04:51,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=8400\tepsilon=0.050\treward/step=-0.99621\tpool_size=10000\tloss ma=0.46532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 8499/10000 [22:16<05:43,  4.37it/s][2016-11-28 02:59:45,641] Making new env: MountainCar-v0\n",
      "[2016-11-28 02:59:45,644] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=8500\tepsilon=0.050\treward/step=-0.99622\tpool_size=10000\tloss ma=0.48778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 02:59:45,910] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 85%|████████▌ | 8501/10000 [22:16<06:45,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -128.200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 8600/10000 [22:37<04:46,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=8600\tepsilon=0.050\treward/step=-0.99622\tpool_size=10000\tloss ma=0.46709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 8701/10000 [22:58<04:17,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=8700\tepsilon=0.050\treward/step=-0.99618\tpool_size=10000\tloss ma=0.44040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 8801/10000 [23:19<04:12,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=8800\tepsilon=0.050\treward/step=-0.99617\tpool_size=10000\tloss ma=0.45874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8900/10000 [23:40<05:07,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=8900\tepsilon=0.050\treward/step=-0.99617\tpool_size=10000\tloss ma=0.47419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 8999/10000 [24:02<03:50,  4.34it/s][2016-11-28 03:01:31,737] Making new env: MountainCar-v0\n",
      "[2016-11-28 03:01:31,741] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=9000\tepsilon=0.050\treward/step=-0.99619\tpool_size=10000\tloss ma=0.44019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:01:32,032] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 90%|█████████ | 9000/10000 [24:02<05:08,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -111.100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 9101/10000 [24:22<02:07,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=9100\tepsilon=0.050\treward/step=-0.99619\tpool_size=10000\tloss ma=0.43853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 9201/10000 [24:36<01:44,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=9200\tepsilon=0.050\treward/step=-0.99620\tpool_size=10000\tloss ma=0.40515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 9301/10000 [24:50<01:39,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=9300\tepsilon=0.050\treward/step=-0.99623\tpool_size=10000\tloss ma=0.46893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 9401/10000 [25:05<01:34,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=9400\tepsilon=0.050\treward/step=-0.99624\tpool_size=10000\tloss ma=0.48686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 9499/10000 [25:20<01:07,  7.47it/s][2016-11-28 03:02:49,928] Making new env: MountainCar-v0\n",
      "[2016-11-28 03:02:49,930] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=9500\tepsilon=0.050\treward/step=-0.99621\tpool_size=10000\tloss ma=0.47175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:02:50,158] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      " 95%|█████████▌| 9501/10000 [25:21<01:33,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -114.700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 9601/10000 [25:40<01:23,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=9600\tepsilon=0.050\treward/step=-0.99624\tpool_size=10000\tloss ma=0.48683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 9701/10000 [26:00<00:57,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=9700\tepsilon=0.050\treward/step=-0.99624\tpool_size=10000\tloss ma=0.52578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 9801/10000 [26:22<00:33,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=9800\tepsilon=0.050\treward/step=-0.99624\tpool_size=10000\tloss ma=0.52794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 9901/10000 [26:43<00:18,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=9900\tepsilon=0.050\treward/step=-0.99623\tpool_size=10000\tloss ma=0.49162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 9999/10000 [27:03<00:00,  5.69it/s][2016-11-28 03:04:32,474] Making new env: MountainCar-v0\n",
      "[2016-11-28 03:04:32,478] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=10000\tepsilon=0.050\treward/step=-0.99623\tpool_size=10000\tloss ma=0.47145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-28 03:04:32,709] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/drqn/records')\n",
      "100%|██████████| 10000/10000 [27:03<00:00,  4.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -108.700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#the loop may take eons to finish.\n",
    "#consider interrupting early.\n",
    "loss = 0\n",
    "for i in tqdm(range(10000)):    \n",
    "    \n",
    "    \n",
    "    #train\n",
    "    for i in range(10):\n",
    "        pool.update(SEQ_LENGTH,append=True,)\n",
    "    for i in range(10):\n",
    "        loss = loss*0.99 + train_step()*0.01\n",
    "        \n",
    "    \n",
    "    \n",
    "    if epoch_counter%100==0:\n",
    "        #average reward per game tick in current experience replay pool\n",
    "        pool_mean_reward = np.average(pool.experience_replay.rewards.get_value()[:,:-1],\n",
    "                                      weights=1+pool.experience_replay.is_alive.get_value()[:,:-1])\n",
    "        pool_size = pool.experience_replay.rewards.get_value().shape[0]\n",
    "        print(\"iter=%i\\tepsilon=%.3f\\treward/step=%.5f\\tpool_size=%i\\tloss ma=%.5f\"%(epoch_counter,\n",
    "                                                         epsilon.get_value(),\n",
    "                                                         pool_mean_reward,\n",
    "                                                         pool_size,\n",
    "                                                         loss))\n",
    "        \n",
    "\n",
    "    ##record current learning progress and show learning curves\n",
    "    if epoch_counter%500 ==0:\n",
    "        n_games = 10\n",
    "        epsilon.set_value(0)\n",
    "        rewards[epoch_counter] = pool.evaluate( record_video=False,n_games=n_games,verbose=False)\n",
    "        print(\"Current score(mean over %i) = %.3f\"%(n_games,np.mean(rewards[epoch_counter])))\n",
    "        epsilon.set_value(0.05)\n",
    "    \n",
    "    \n",
    "    epoch_counter  +=1\n",
    "\n",
    "    \n",
    "# Time to drink some coffee!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iters,session_rewards=zip(*sorted(rewards.items(),key=lambda (k,v):k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f544c146b90>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEACAYAAACgS0HpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/j/tUPTqfYd62AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f544c9b8990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(iters,map(np.mean,session_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
